{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDVI Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "import sentinelsat\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import os\n",
    "import lithops\n",
    "import random\n",
    "import rasterio\n",
    "import re\n",
    "import tempfile\n",
    "import zipfile\n",
    "import subprocess\n",
    "import glob\n",
    "import json\n",
    "from rio_cogeo import cogeo\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "from fiona.io import ZipMemoryFile\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.io import MemoryFile\n",
    "from zipfile import ZipFile\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles\n",
    "from lithops import Storage\n",
    "\n",
    "from cloudbutton_geospatial.utils import notebook as notebook_utils\n",
    "from cloudbutton_geospatial.io_utils.ndvi import get_ndvi_params, ndvi_calculation, ndvi_tile_sentinel, get_subset_raster, lonlat_to_utm, get_poly_within\n",
    "from cloudbutton_geospatial.io_utils.plot import tiff_overview, plot_map\n",
    "\n",
    "os.environ['CURL_CA_BUNDLE'] = '/etc/ssl/certs/ca-certificates.crt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the environmental variables *SENTINEL_USERNAME* and *SENTINEL_PASSWORD* to match your Sentinel-2 credentials. You can register and access data for free at https://sentinel.esa.int/web/sentinel/sentinel-data-access/registration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTINEL_USERNAME = '<>'\n",
    "SENTINEL_PASSWORD = '<>'\n",
    "STORAGE_BUCKET = 'geospatial-usecase'\n",
    "COMPUTE_BACKEND = 'ibm_cf'\n",
    "STORAGE_BACKEND = 'ibm_cos'\n",
    "RUNTIME = 'jsampe/lithops-ibmcf-geospatial-v38:07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_storage = Storage(backend=STORAGE_BACKEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the date interval in which tiles will be processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fb5b804cb54fe9915aa415df825023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=datetime.date(2020, 12, 1), description='From day')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0448d17585084e32a79866024e2b1c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=datetime.date(2020, 12, 31), description='To day')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from_day, to_day = notebook_utils.pick_date_range()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the tile's cloud percentage threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad4422620254eb38b05071d4de08a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=15, continuous_update=False, description='Porcentaje de nubosidad')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "percentage = notebook_utils.pick_percentage_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the area which delimites the tiles you want to process (left click to mark a point in the map, right click to erase current selection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_region = notebook_utils.MapRegion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sentinel-2 metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# locations = map_region.get_region()\n",
    "\n",
    "# Tarragona data\n",
    "locations = [[1.5481363013595886, 41.16508628430497],\n",
    " [0.8177319989996914, 40.62111912603713],\n",
    " [0.6008074129604647, 40.60652433834119],\n",
    " [0.4552757286556909, 40.868742532626996],\n",
    " [0.3811369460853299, 41.03883697553436],\n",
    " [0.427816920296289, 41.247740935856484],\n",
    " [0.694167361382423, 41.33441592882952],\n",
    " [1.097811844265526, 41.39831645175795],\n",
    " [1.452030472101722, 41.365343372983396],\n",
    " [1.5481363013595886, 41.16508628430497]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_json_area = {\n",
    "    \"features\": [\n",
    "        {\n",
    "            \"geometry\": {\n",
    "                \"coordinates\":[locations],\n",
    "                \"type\": \"Polygon\"\n",
    "            },\n",
    "            \"properties\": {},\n",
    "            \"type\": \"Feature\"\n",
    "        }\n",
    "    ],\n",
    "    \"type\": \"FeatureCollection\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the selected parameters, get the identifiers of the selected tiles from Sentinel-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnauthorizedError",
     "evalue": "Invalid user name or password. Note that account creation and password changes may take up to a week to propagate to the 'https://apihub.copernicus.eu/apihub/' API URL you are using. Consider switching to 'https://scihub.copernicus.eu/dhus/' instead in the mean time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sentinelsat/sentinel.py\u001b[0m in \u001b[0;36m_check_scihub_response\u001b[0;34m(response, test_json, query_string)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest_json\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://apihub.copernicus.eu/apihub/search?format=json&rows=100&start=0&q=beginPosition%3A%5B%222020-12-01T00%3A00%3A00Z%22+TO+%222020-12-31T00%3A00%3A00Z%22%5D+cloudcoverpercentage%3A%5B%220%22+TO+%2215%22%5D+platformname%3A%22Sentinel-2%22+producttype%3A%5B%22S2MS2Ap%22+TO+%22S2MSI1C%22%5D+footprint%3A%22Intersects%28GEOMETRYCOLLECTION%28POLYGON%28%281.5481+41.1651%2C0.8177+40.6211%2C0.6008+40.6065%2C0.4553+40.8687%2C0.3811+41.0388%2C0.4278+41.2477%2C0.6942+41.3344%2C1.0978+41.3983%2C1.4520+41.3653%2C1.5481+41.1651%29%29%29%29%22",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnauthorizedError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2478966/4100912374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                       api_url=\"https://apihub.copernicus.eu/apihub/\")\n\u001b[1;32m      4\u001b[0m \u001b[0mfootprint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentinelsat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeojson_to_wkt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_json_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m products = sentinel_api.query(footprint,\n\u001b[0m\u001b[1;32m      6\u001b[0m                               \u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mplatformname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sentinel-2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sentinelsat/sentinel.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, area, date, raw, area_relation, order_by, limit, offset, **keywords)\u001b[0m\n\u001b[1;32m    284\u001b[0m         )\n\u001b[1;32m    285\u001b[0m         \u001b[0mformatted_order_by\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_order_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder_by\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatted_order_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {count:,} products\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_parse_opensearch_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sentinelsat/sentinel.py\u001b[0m in \u001b[0;36m_load_query\u001b[0;34m(self, query, order_by, limit, offset)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mproducts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_subquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_by\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;31m# repeat query until all results have been loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sentinelsat/sentinel.py\u001b[0m in \u001b[0;36m_load_subquery\u001b[0;34m(self, query, order_by, limit, offset)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl_limit_semaphore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"q\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"latin1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_scihub_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;31m# store last status code (for testing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sentinelsat/sentinel.py\u001b[0m in \u001b[0;36m_check_scihub_response\u001b[0;34m(response, test_json, query_string)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                         \u001b[0;34m\"Consider switching to 'https://scihub.copernicus.eu/dhus/' instead in the mean time.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                     )\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnauthorizedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"Request Entity Too Large\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"Request-URI Too Long\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Server was unable to process the query due to its excessive length\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnauthorizedError\u001b[0m: Invalid user name or password. Note that account creation and password changes may take up to a week to propagate to the 'https://apihub.copernicus.eu/apihub/' API URL you are using. Consider switching to 'https://scihub.copernicus.eu/dhus/' instead in the mean time."
     ]
    }
   ],
   "source": [
    "sentinel_api = sentinelsat.SentinelAPI(user=SENTINEL_USERNAME,\n",
    "                                       password=SENTINEL_PASSWORD,\n",
    "                                      api_url=\"https://apihub.copernicus.eu/apihub/\")\n",
    "footprint = sentinelsat.geojson_to_wkt(geo_json_area)\n",
    "products = sentinel_api.query(footprint,\n",
    "                              date=(from_day.value, to_day.value),\n",
    "                              platformname='Sentinel-2',\n",
    "                              producttype=('S2MS2Ap', 'S2MSI1C'),\n",
    "                              cloudcoverpercentage=(0, percentage.value))\n",
    "geojson_products = sentinel_api.to_geojson(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# geojson_products = [geojson_products[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of tiles: {}'.format(len(geojson_products)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Athmospheric correction using Serverful Lithops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will download tile images from Sentinel2 using the previously selected configuration and apply athmospheric correction.\n",
    "\n",
    "This process is not parallelizable and lasts for over 20 minutes, so it is not suited for serverless functions. We will use Lithops Standalone instead, which uses serverful instances that haven't time limits.\n",
    "\n",
    "The runtime used packs Sentinel2 software and IBM Cloud Functions Python3.7 handler in a Dockerfile located in `sentinel2_runtime/Dockerfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jp2_to_cog(band_src_path):\n",
    "    \"\"\"\n",
    "    Transform a sentinel2 band (.jp2) to GeoTiff (.tif)\n",
    "    \"\"\"\n",
    "    config = dict(NUM_THREADS=100, GDAL_TIFF_OVR_BLOCKSIZE=128)\n",
    "\n",
    "    output_profile = {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"interleave\": \"pixel\",\n",
    "        \"tiled\": True,\n",
    "        \"blockxsize\": 256,\n",
    "        \"blockysize\": 256,\n",
    "        \"compress\": \"DEFLATE\",\n",
    "    }\n",
    "\n",
    "    cog_path = f\"{band_src_path[band_src_path.rfind('/')+1:band_src_path.rfind('.')]}.tif\"\n",
    "    cogeo.cog_translate(\n",
    "        band_src_path,\n",
    "        cog_path,\n",
    "        output_profile,\n",
    "        nodata=0,\n",
    "        in_memory=False,\n",
    "        config=config,\n",
    "        quiet=True,\n",
    "    )\n",
    "\n",
    "    return cog_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_atmospheric_correction(product_geojson, storage):\n",
    "    product = product_geojson['properties']\n",
    "    tile = product['filename'][39:44]\n",
    "    date = product['filename'][11:19]\n",
    "\n",
    "    # Check if tile is already processed stored in COS, return if it is\n",
    "    #keys = storage.list_keys(bucket=STORAGE_BUCKET)\n",
    "    keys = []\n",
    "    pattern = r\".*\" + re.escape(date) + r\".*\" + re.escape(tile) + r\".*\\.geojson\"\n",
    "    filtered = [file for file in keys if re.search(pattern, file)]\n",
    "    if filtered:\n",
    "        print('Tile already in COS: {}'.format(filtered))\n",
    "        remote_geotiff = filtered.pop()\n",
    "        return remote_geotiff\n",
    "\n",
    "    # Download Sentinel-2 tile\n",
    "    sentinel_api = sentinelsat.SentinelAPI(user=os.environ[\"SENTINEL_USERNAME\"],\n",
    "                                           password=os.environ[\"SENTINEL_PASSWORD\"])\n",
    "\n",
    "    sentinel_product_dir = product['filename']\n",
    "    tmpdir = tempfile.gettempdir()\n",
    "    d_meta = sentinel_api.download(product['uuid'], directory_path=tmpdir)\n",
    "    \n",
    "    if d_meta['downloaded_bytes'] == 0:\n",
    "        raise Exception(d_meta)\n",
    "    \n",
    "    # Extract and remove zip file\n",
    "    zip_ref = zipfile.ZipFile(d_meta['path'])\n",
    "    zip_ref.extractall(tmpdir)\n",
    "    zip_ref.close()\n",
    "    #os.remove(d_meta['path'])\n",
    "\n",
    "    # Atmospheric correction\n",
    "    sentinel_product_dir = os.path.join(tmpdir, product['filename'])\n",
    "    corrected_images = glob.glob(f\"*2A_{date}*_T{tile}_*.SAFE/GRANULE/*/IMG_DATA/R10m/*B0[48]*.jp2\")\n",
    "    atmospheric_corrected = corrected_images[0] if len(corrected_images) > 0 else None\n",
    "\n",
    "    if not atmospheric_corrected:\n",
    "        print(f'Doing the atmospheric correction for {sentinel_product_dir}')\n",
    "        try:\n",
    "            cmd = ['L2A_Process --resolution 10 {}'.format(sentinel_product_dir)]\n",
    "            val = subprocess.check_output(cmd, stderr=subprocess.STDOUT, shell=True, universal_newlines=True)\n",
    "            corrected_images = glob.glob(f\"*2A_{date}*_T{tile}_*.SAFE/GRANULE/*/IMG_DATA/R10m/*B0[48]*.jp2\")\n",
    "            print(f'Atmospheric correction finished {val}')\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(e.returncode)\n",
    "            print(e.output)\n",
    "            print(e.stderr)\n",
    "            raise(e)\n",
    "\n",
    "\n",
    "    # Translate bands in .jp2 to GeoTiff format\n",
    "    band_files = []\n",
    "    band4 = glob.glob(os.path.join(tmpdir, '*L2A_{}*_T{}*.SAFE/GRANULE/*/IMG_DATA/R10m/*B04*'.format(date, tile))).pop()\n",
    "    band8 = glob.glob(os.path.join(tmpdir, '*L2A_{}*_T{}*.SAFE/GRANULE/*/IMG_DATA/R10m/*B08*'.format(date, tile))).pop()\n",
    "\n",
    "    if band4 is not None and band8 is not None:\n",
    "        band4_tiff_file = f\"{band4[band4.rfind('/')+1:band4.rfind('.')]}.tif\"\n",
    "        band8_tiff_file = f\"{band8[band8.rfind('/') + 1:band8.rfind('.')]}.tif\"\n",
    "        jp2_to_cog(band4)\n",
    "        jp2_to_cog(band8)\n",
    "        band_files.append(band4_tiff_file)\n",
    "        band_files.append(band8_tiff_file)\n",
    "    \n",
    "    print(band_files)\n",
    "\n",
    "    # Merge both bands into a single geotiff\n",
    "    combined_geotiff_key = band_files[0][0:22] + '_COMBINED.tif'\n",
    "    with rasterio.open(band_files[0]) as src:\n",
    "        profile = src.profile\n",
    "        profile.update(count=len(band_files))\n",
    "\n",
    "    with rasterio.open(combined_geotiff_key, 'w', **profile) as dst:\n",
    "        for i, band_file in enumerate(band_files):\n",
    "            with rasterio.open(band_file) as src:\n",
    "                dst.write(src.read(1), i + 1)\n",
    "\n",
    "    # Upload generated files to Cloud Storage\n",
    "    with open(combined_geotiff_key, 'rb') as combined_geotiff_f:\n",
    "        storage.put_object(bucket=STORAGE_BUCKET, key=combined_geotiff_key, body=combined_geotiff_f)\n",
    "    product_meta_key = combined_geotiff_key + '.meta.json'\n",
    "    storage.put_object(bucket=STORAGE_BUCKET, key=product_meta_key, body=json.dumps(product))\n",
    "\n",
    "    return combined_geotiff_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec = lithops.FunctionExecutor(backend=COMPUTE_BACKEND, storage=STORAGE_BACKEND,\n",
    "                                 runtime=RUNTIME, \n",
    "                                 workers=1, log_level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extra_env = {'SENTINEL_USERNAME': SENTINEL_USERNAME,\n",
    "             'SENTINEL_PASSWORD': SENTINEL_PASSWORD}\n",
    "\n",
    "fexec.map(perform_atmospheric_correction, geojson_products[\"features\"],\n",
    "          extra_env=extra_env, chunksize=len(geojson_products[\"features\"]))\n",
    "combined_keys = fexec.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDVI Computation using Serverless Lithops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate NDVI index of tiles tha thave been downloaded and pre-processed before.\n",
    "\n",
    "This process can be executed in parallel (for every tile) and in serverless functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec = lithops.FunctionExecutor(backend=COMPUTE_BACKEND, storage=STORAGE_BACKEND,\n",
    "                                 runtime=RUNTIME, runtime_memory=2048, log_level='DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# combined_keys = ['T30SXG_20201229T110451_COMBINED.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi(combined_key, storage):\n",
    "    tmpdir = tempfile.gettempdir()\n",
    "    dat = storage.get_object(bucket=STORAGE_BUCKET, key=combined_key, stream=True)\n",
    "    out = os.path.join(tmpdir, 'out.tif')\n",
    "\n",
    "    with rasterio.open(dat) as src:\n",
    "        profile = src.profile\n",
    "        profile.update(dtype='float32')\n",
    "        profile.update(count=1)\n",
    "        with rasterio.open(out, 'w', **profile) as dst:\n",
    "            for _, window in src.block_windows(1):\n",
    "                red = src.read(1, window=window).astype('float32')\n",
    "                nir = src.read(2, window=window).astype('float32')\n",
    "                ndvi = (np.where((nir + red) == 0., 0,\n",
    "                                 (nir - red) / (nir + red))).astype('float32')\n",
    "                dst.write(ndvi, 1, window=window)\n",
    "\n",
    "    prefix = combined_key.rsplit('_', 1)[0]\n",
    "    output_key = prefix + '_NDVI.tif'\n",
    "    with open(out, 'rb') as output_f:\n",
    "        storage.put_object(bucket=STORAGE_BUCKET, key=output_key, body=output_f)\n",
    "\n",
    "    return output_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec.map(ndvi, combined_keys, timeout=60)\n",
    "ndvi_keys = fexec.get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# ndvi_keys = ['T30SXG_20201229T110451_NDVI.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_select = notebook_utils.pick_tile(ndvi_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = cloud_storage.get_object(bucket=STORAGE_BUCKET, key=tile_select.value, stream=True)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20,15))\n",
    "\n",
    "with rasterio.open(obj) as src:\n",
    "#     ij, window = random.choice(list(src.block_windows()))\n",
    "#     arr = src.read(1, window=window)\n",
    "    arr = src.read(1)\n",
    "    plt.imshow(arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
