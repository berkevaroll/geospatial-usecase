{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.8.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# Water consumption", "metadata": {}}, {"cell_type": "markdown", "source": "The current notebook computes an interpolation of temperatures in each pixel based on SIAM extracted data.", "metadata": {}}, {"cell_type": "markdown", "source": "A .bluemix/cos_credentials.json file correctly configured located at home directory is needed in order to connect with IBM Cloud. More information at https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-service-credentials.", "metadata": {}}, {"cell_type": "code", "source": "from collections import defaultdict\nfrom ibm_botocore.client import Config, ClientError\nfrom geospatial_usecase.io_utils.cos import COS\nfrom geospatial_usecase.io_utils.plot import plot_random_blocks, plot_results\nfrom rasterio.windows import Window\nfrom scipy.spatial import distance_matrix\nfrom shapely.geometry import Point, MultiPoint, box\nfrom pprint import pprint\n\nimport os\nimport ibm_boto3\nimport math\nimport numpy as np\nimport pandas as pd\nimport lithops\nimport requests\nimport rasterio\nimport json\nimport random\n\nfrom lithops.storage import Storage", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:27.706148Z", "start_time": "2021-04-13T14:38:27.027515Z"}, "tags": [], "trusted": true}, "execution_count": 1, "outputs": []}, {"cell_type": "markdown", "source": "## Global parameters", "metadata": {}}, {"cell_type": "markdown", "source": "Area outside the processed tile that we want to consider for taking SIAM stations into account:", "metadata": {}}, {"cell_type": "code", "source": "AREA_OF_INFLUENCE = 4000", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:28.795793Z", "start_time": "2021-04-13T14:38:28.788173Z"}, "trusted": true}, "execution_count": 2, "outputs": []}, {"cell_type": "markdown", "source": "IBM Cos bucket to upload files:", "metadata": {}}, {"cell_type": "code", "source": "BUCKET = 'geospatial-usecase'", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:29.658886Z", "start_time": "2021-04-13T14:38:29.654251Z"}, "trusted": true}, "execution_count": 3, "outputs": []}, {"cell_type": "markdown", "source": "Runtime name", "metadata": {}}, {"cell_type": "code", "source": "RUNTIME = 'sergidomingo/geospatial-k8s:2'\n# RUNTIME = 'sergidomingo/geospatial-k8s:jt1' \n# RUNTIME = 'jsampe/lithops-k8s-geospatial'", "metadata": {"trusted": true}, "execution_count": 4, "outputs": []}, {"cell_type": "markdown", "source": "Split tile into SPLITS$^2$ chunks:", "metadata": {}}, {"cell_type": "code", "source": "#SPLITS = 3\nSPLITS = 3", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:30.525082Z", "start_time": "2021-04-13T14:38:30.519883Z"}, "trusted": true}, "execution_count": 5, "outputs": []}, {"cell_type": "markdown", "source": "Correlation coefficient between elevation and temperature:", "metadata": {}}, {"cell_type": "code", "source": "r = -0.0056", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:31.362634Z", "start_time": "2021-04-13T14:38:31.359578Z"}, "trusted": true}, "execution_count": 6, "outputs": []}, {"cell_type": "markdown", "source": "Elevation to interpolate temperature:", "metadata": {}}, {"cell_type": "code", "source": "zdet = 2000", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:32.187402Z", "start_time": "2021-04-13T14:38:32.184798Z"}, "trusted": true}, "execution_count": 7, "outputs": []}, {"cell_type": "markdown", "source": "Day of year to calculate solar irradiation:", "metadata": {}}, {"cell_type": "code", "source": "DAY_OF_YEAR = 50", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:33.304420Z", "start_time": "2021-04-13T14:38:33.299098Z"}, "trusted": true}, "execution_count": 8, "outputs": []}, {"cell_type": "markdown", "source": "Object storage key prefix, to keep objects organized:", "metadata": {}}, {"cell_type": "code", "source": "cloud_storage = Storage(backend=\"ceph\")", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:34.978991Z", "start_time": "2021-04-13T14:38:34.905888Z"}, "trusted": true}, "execution_count": 9, "outputs": []}, {"cell_type": "markdown", "source": "## Data preparation", "metadata": {}}, {"cell_type": "markdown", "source": "This section fetches and uploads to COS the metadata used in the workflow. It can be skipped if the data is already in COS.", "metadata": {}}, {"cell_type": "markdown", "source": "### SIAM data", "metadata": {}}, {"cell_type": "code", "source": "url = 'http://siam.imida.es/apex/f?p=101:47:493289053024037:CSV::::'\n# url = 'http://siam.imida.es/apex/f?p=101:48:2555846978143339:CSV::::'\nsiam_data = requests.get(url)\nwith open('geospatial_usecase/siam_data.csv', 'wb') as siam_data_file:\n    siam_data_file.write(siam_data.content)", "metadata": {"ExecuteTime": {"end_time": "2021-04-07T09:42:03.976592Z", "start_time": "2021-04-07T09:42:02.944388Z"}, "tags": [], "trusted": true}, "execution_count": 10, "outputs": []}, {"cell_type": "code", "source": "def guess_nearest(x, y, field, stations):\n    '''\n    Compute field value at a given x,y point by getting the value of the closest station \n    '''\n    from shapely.ops import nearest_points\n    stations_of_interest = stations[(stations[field] != '-') & ((stations['X'] != x) | (stations['Y'] != y))]\n    points = MultiPoint(stations_of_interest.apply(lambda row: Point(row['X'], row['Y']), axis=1 ).array)\n    nearest = nearest_points(Point(x,y), points)[1]\n    val = stations_of_interest[(stations_of_interest['X'] == nearest.x) &\n                                (stations_of_interest['Y'] == nearest.y)]\n\n    return stations_of_interest[(stations_of_interest['X'] == nearest.x) &\n                                (stations_of_interest['Y'] == nearest.y)][field].iloc[0] ", "metadata": {"ExecuteTime": {"end_time": "2021-04-07T09:42:06.892586Z", "start_time": "2021-04-07T09:42:06.886566Z"}, "trusted": true}, "execution_count": 11, "outputs": []}, {"cell_type": "markdown", "source": "Append locations of SIAM stations to previously downloaded data and write results to a CSV:", "metadata": {}}, {"cell_type": "code", "source": "columns = {\n    'Estaci\u00f3n': 'COD',\n    'Tmed <br> (\u00baC)': 'temp',\n    'Hrmed <br> (%)': 'hr',\n    'Vvmed <br> (m/seg)': 'v',\n    'Eti.': 'dir',\n    'Radmed <br> (w/m2)': 'rad',\n    'Dvmed <br>  (\u00ba)': 'dir_deg'\n}\n\nsiam_data = pd.read_csv('geospatial_usecase/siam_data.csv', encoding='iso-8859-1',\n                        sep=';', decimal=',', thousands='.', na_values = '-')\nsiam_data = siam_data[columns.keys()].rename(columns=columns)\nsiam_locations = pd.read_csv('geospatial_usecase/siam_locations.csv', encoding='iso-8859-1', sep=';', decimal = ',', thousands='.')\nsiam = pd.merge(siam_locations, siam_data, on='COD')\nsiam['tdet'] = siam['temp'] + r * (zdet - siam['Cota'].to_numpy())\nsiam = siam[['X', 'Y', 'Cota', 'temp', 'hr', 'tdet', 'v'] + list(columns.values())]\n# Guess wind direction of undefined values\nsiam['dir_deg'] = siam.apply(lambda row: row['dir_deg'] \n                                     if not math.isnan(row['dir_deg'])\n                                     else guess_nearest(row['X'], row['Y'], 'dir_deg', siam), axis=1)\n# Guess radiation of undefined values\nsiam['rad'] = siam.apply(lambda row: row['rad'] \n                                     if not math.isnan(row['rad'])\n                                     else guess_nearest(row['X'], row['Y'], 'rad', siam), axis=1)\nsiam.to_csv('geospatial_usecase/siam.csv', index=False)", "metadata": {"ExecuteTime": {"end_time": "2021-04-07T09:42:12.829971Z", "start_time": "2021-04-07T09:42:12.755771Z"}, "trusted": true}, "execution_count": 12, "outputs": []}, {"cell_type": "markdown", "source": "Upload the output CSV to COS:", "metadata": {}}, {"cell_type": "code", "source": "with open('geospatial_usecase/siam.csv', 'rb') as siam_out_file:\n    cloud_storage.put_object(bucket=BUCKET, key='siam.csv', body=siam_out_file)", "metadata": {"ExecuteTime": {"end_time": "2021-04-07T09:46:49.948481Z", "start_time": "2021-04-07T09:46:49.800147Z"}, "trusted": true}, "execution_count": 13, "outputs": []}, {"cell_type": "markdown", "source": "### MDT (Modelo digital del terreno) data", "metadata": {}}, {"cell_type": "markdown", "source": "Download MDT files for free from http://centrodedescargas.cnig.es/CentroDescargas/buscadorCatalogo.do?codFamilia=MDT05# and put them in `MDT` folder.", "metadata": {}}, {"cell_type": "markdown", "source": "Find downloaded MDTs:", "metadata": {}}, {"cell_type": "code", "source": "mdt_folder = 'geospatial_usecase/MDT'\nmdts = [os.path.join(mdt_folder, mdt) for mdt in os.listdir(mdt_folder) if mdt.endswith('.asc')]\nmdts", "metadata": {"ExecuteTime": {"end_time": "2021-04-07T09:48:12.000399Z", "start_time": "2021-04-07T09:48:11.986192Z"}, "trusted": true}, "execution_count": 14, "outputs": [{"execution_count": 14, "output_type": "execute_result", "data": {"text/plain": "[]"}, "metadata": {}}]}, {"cell_type": "code", "source": "tiles = [os.path.splitext(os.path.basename(mdt))[0] for mdt in mdts]\ntiles", "metadata": {"ExecuteTime": {"end_time": "2021-04-07T09:48:13.697506Z", "start_time": "2021-04-07T09:48:13.691877Z"}, "trusted": true}, "execution_count": 15, "outputs": [{"execution_count": 15, "output_type": "execute_result", "data": {"text/plain": "[]"}, "metadata": {}}]}, {"cell_type": "markdown", "source": "Convert digital elevation map into a Cloud Optimized Geotiff. Upload then to IBM COS:", "metadata": {}}, {"cell_type": "code", "source": "for mdt in mdts:\n    tiff_file = os.path.splitext(mdt)[0] + '.tif'\n    with rasterio.open(mdt) as src:\n        profile = src.profile\n        # Cloud optimized GeoTiff parameters (No hace falta rio_cogeo)\n        profile.update(driver='GTiff')\n        profile.update(blockxsize=256)\n        profile.update(blockysize=256)\n        profile.update(tiled=True)\n        profile.update(compress='deflate')\n        profile.update(interleave='band')\n        with rasterio.open(tiff_file, \"w\", **profile) as dest:\n            dest.write(src.read())", "metadata": {"ExecuteTime": {"end_time": "2021-04-07T09:49:39.303588Z", "start_time": "2021-04-07T09:48:35.778105Z"}, "trusted": true}, "execution_count": 16, "outputs": []}, {"cell_type": "code", "source": "mdts_gtiff = [os.path.join(mdt_folder, mdt) for mdt in os.listdir(mdt_folder) if mdt.endswith('.tif')]\nmdts_gtiff", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:47.839384Z", "start_time": "2021-04-13T14:38:47.833205Z"}, "trusted": true}, "execution_count": 17, "outputs": [{"execution_count": 17, "output_type": "execute_result", "data": {"text/plain": "[]"}, "metadata": {}}]}, {"cell_type": "code", "source": "for mdt_gtiff in mdts_gtiff:\n    with open(mdt_gtiff, 'rb') as mdt_file:\n        cloud_storage.put_object(bucket=BUCKET, key=mdt_gtiff, body=mdt_file)", "metadata": {"ExecuteTime": {"end_time": "2021-04-07T09:51:19.779414Z", "start_time": "2021-04-07T09:50:38.654162Z"}, "trusted": true}, "execution_count": 18, "outputs": []}, {"cell_type": "markdown", "source": "## Serverless computation", "metadata": {}}, {"cell_type": "markdown", "source": "Input MDT tiles to process:", "metadata": {}}, {"cell_type": "code", "source": "tiles = [os.path.splitext(os.path.basename(key))[0]\n         for key in cloud_storage.list_keys(bucket=BUCKET, prefix='MDT')]\ntiles", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:50.635461Z", "start_time": "2021-04-13T14:38:50.327866Z"}, "trusted": true}, "execution_count": 19, "outputs": [{"execution_count": 19, "output_type": "execute_result", "data": {"text/plain": "['PNOA_MDT05_ETRS89_HU30_0891_LID',\n 'PNOA_MDT05_ETRS89_HU30_0892_LID',\n 'PNOA_MDT05_ETRS89_HU30_0912_LID',\n 'PNOA_MDT05_ETRS89_HU30_0913_LID',\n 'PNOA_MDT05_ETRS89_HU30_0933_LID',\n 'PNOA_MDT05_ETRS89_HU30_0934_LID',\n 'PNOA_MDT05_ETRS89_HU30_0954_LID',\n 'PNOA_MDT05_ETRS89_HU30_0955_LID']"}, "metadata": {}}]}, {"cell_type": "code", "source": "#DEBUG\n#tiles = ['PNOA_MDT05_ETRS89_HU30_0891_LID']\n#tiles = ['PNOA_MDT05_ETRS89_HU30_0911_LID','PNOA_MDT05_ETRS89_HU30_0868_LID','PNOA_MDT05_ETRS89_HU30_0910_LID']\n#tiles", "metadata": {"ExecuteTime": {"end_time": "2021-03-29T10:06:07.523375Z", "start_time": "2021-03-29T10:05:14.468Z"}, "trusted": true}, "execution_count": 20, "outputs": []}, {"cell_type": "markdown", "source": "Compute solar irradiation given a day of year using GRASS libraries:", "metadata": {}}, {"cell_type": "code", "source": "def compute_solar_irradiation(inputFile, outputFile, crs='32630'):\n    # Define grass working set\n    GRASS_GISDB = 'grassdata'\n    GRASS_LOCATION = 'GEOPROCESSING'\n    GRASS_MAPSET = 'PERMANENT'\n    GRASS_ELEVATIONS_FILENAME = 'ELEVATIONS'\n    \n    import os\n    import shutil\n    os.environ['GRASSBIN'] = 'grass76'\n    from grass_session import Session\n    import grass.script as gscript\n    from grass.pygrass.modules.shortcuts import general as g\n    from grass.pygrass.modules.shortcuts import raster as r\n    import re\n    os.environ.update(dict(GRASS_COMPRESS_NULLS='1'))\n    \n    # Clean previously processed data\n    if os.path.isdir(GRASS_GISDB):\n        shutil.rmtree(GRASS_GISDB)\n    with Session(gisdb=GRASS_GISDB, location=GRASS_LOCATION, mapset=GRASS_MAPSET, create_opts='EPSG:32630') as ses:\n    \n        # Set project projection to match elevation raster projection\n        g.proj(epsg=crs, flags='c') \n    \n        # Load raster file into working directory\n        r.import_(input=inputFile, \n                  output=GRASS_ELEVATIONS_FILENAME, \n                  flags='o')    \n        \n        # Set project region to match raster region\n        g.region(raster=GRASS_ELEVATIONS_FILENAME, flags='s')    \n        # Calculate solar irradiation\n        gscript.run_command('r.slope.aspect', elevation=GRASS_ELEVATIONS_FILENAME,\n                            slope='slope', aspect='aspect')\n        gscript.run_command('r.sun', elevation=GRASS_ELEVATIONS_FILENAME,\n                            slope='slope', aspect='aspect', beam_rad='beam',\n                            step=1, day=DAY_OF_YEAR)\n        \n        # Get extraterrestrial irradiation from history metadata\n        regex = re.compile(r'\\d+\\.\\d+')\n        output = gscript.read_command(\"r.info\", flags=\"h\", map=[\"beam\"])\n        splits = str(output).split('\\n')\n        line = next(filter(lambda line: 'Extraterrestrial' in line, splits))\n        extraterrestrial_irradiance = float(regex.search(line)[0])\n        \n        # Export generated results into a GeoTiff file\n        if os.path.isfile(outputFile):\n            os.remove(outputFile)\n            \n        r.out_gdal(input='beam', output=outputFile)\n        \n        return extraterrestrial_irradiance", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:54.462039Z", "start_time": "2021-04-13T14:38:54.449706Z"}, "tags": [], "trusted": true}, "execution_count": 21, "outputs": []}, {"cell_type": "markdown", "source": "Get stations contained in the area of interest:", "metadata": {}}, {"cell_type": "code", "source": "def filter_stations(bounds, stations):\n    total_points = MultiPoint([Point(x,y) for x, y in stations[['X', 'Y']].to_numpy()])\n    intersection = bounds.buffer(AREA_OF_INFLUENCE).intersection(total_points)\n    \n    return stations[[ intersection.contains(point) for point in total_points]]", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:55.461635Z", "start_time": "2021-04-13T14:38:55.457230Z"}, "trusted": true}, "execution_count": 22, "outputs": []}, {"cell_type": "markdown", "source": "Inverse Distance Weighting interpolation:", "metadata": {}}, {"cell_type": "code", "source": "def compute_basic_interpolation(shape, stations, field_value, offset = (0,0)):\n    station_pixels = [[pixel[0], pixel[1]] for pixel in stations['pixel'].to_numpy()]\n    \n    # Get an array where each position represents pixel coordinates\n    tile_pixels = np.indices(shape).transpose(1,2,0).reshape(shape[0]*shape[1], 2) + offset\n    dist = distance_matrix(station_pixels, tile_pixels)\n    weights = np.where(dist == 0, np.finfo('float32').max, 1.0 / dist )\n    weights /=  weights.sum(axis=0)\n    \n    return np.dot(weights.T, stations[field_value].to_numpy()).reshape(shape).astype('float32')", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:58.209269Z", "start_time": "2021-04-13T14:38:58.202597Z"}, "trusted": true}, "execution_count": 23, "outputs": []}, {"cell_type": "markdown", "source": "Interpolate temperatures from a subset of the tile:", "metadata": {}}, {"cell_type": "code", "source": "def radiation_interpolation(obj, block_x, block_y, splits, storage):\n    tile_key = os.path.basename(obj.key)\n    tile_id, _ = os.path.splitext(tile_key)\n    \n    with rasterio.open(obj.data_stream) as src:\n        transform = src.transform\n        \n        # Compute working window\n        step_w = src.width / splits\n        step_h = src.height / splits\n        \n        offset_h = round(step_h * block_x)\n        offset_w = round(step_w * block_y)\n        \n        profile = src.profile\n        width = math.ceil(step_w * (block_y + 1) - offset_w)\n        height = math.ceil(step_h * (block_x + 1) - offset_h)\n        \n        profile.update(width=width)\n        profile.update(height=height)\n        \n        window = Window(offset_w, offset_h, width, height)\n        \n        with rasterio.open('input', 'w', **profile) as dest:\n            dest.write(src.read(window=window))\n        \n    # Stores global irradiation at \"output\", it also returns extraterrestrial irradiation\n    extraterrestrial_irradiation = compute_solar_irradiation('input', 'output')\n        \n    # Create and store a raster with extraterrestrial_irradiation\n    with rasterio.open('extr', 'w', **profile) as dest:\n        data = np.full((height, width), extraterrestrial_irradiation, dtype='float32')\n        dest.write(data, 1)\n        \n    out_key = os.path.join('tmp', 'extrad', tile_id, f'chunk_{block_x}-{block_y}') + '.tif'\n    with open('extr', 'rb') as out_file:\n        storage.put_object(BUCKET, out_key, out_file)\n    \n    out_key = os.path.join('tmp', 'rad', tile_id, f'chunk_{block_x}-{block_y}') + '.tif'\n    with open('output', 'rb') as out_file:\n        storage.put_object(BUCKET, out_key, out_file)\n    \n    return out_key", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:38:59.031150Z", "start_time": "2021-04-13T14:38:59.005158Z"}, "trusted": true}, "execution_count": 24, "outputs": []}, {"cell_type": "code", "source": "def map_interpolation(obj, block_x, block_y, splits, data_field, storage):\n    import io\n    import math\n    import numpy as np\n    \n    tile_key = os.path.basename(obj.key)\n    tile_id, _ = os.path.splitext(tile_key)\n          \n    siam_stream = storage.get_object(BUCKET, 'siam.csv', stream=True)\n    siam = pd.read_csv(siam_stream)\n    \n    with rasterio.open(obj.data_stream) as src:\n        transform = src.transform\n        \n        # Compute working window\n        step_w = src.width / splits\n        step_h = src.height / splits\n        \n        offset_h = round(step_h * block_x)\n        offset_w = round(step_w * block_y)\n        \n        profile = src.profile\n        \n        width = math.ceil(step_w * (block_y + 1) - offset_w)\n        height = math.ceil(step_h * (block_x + 1) - offset_h)\n        \n        profile.update(width=width)\n        profile.update(height=height)\n        \n        window = Window(offset_w,offset_h, width, height)\n        \n        # Filter desired stations\n        bounding_rect = box(src.bounds.left, src.bounds.top, src.bounds.right, src.bounds.bottom)\n        filtered = pd.DataFrame(filter_stations(bounding_rect, siam))\n        filtered['pixel'] = filtered.apply(\n            lambda station: rasterio.transform.rowcol(transform, station['X'], station['Y']), axis=1)\n        \n        # Interpolate and write results \n        with rasterio.open('output', 'w', **profile) as dest:\n            if data_field == 'temp':\n                elevations = src.read(1, window=window) # Get elevations content\n                interpolation = compute_basic_interpolation(elevations.shape, filtered,\n                                                            'tdet', (offset_h, offset_w))\n                interpolation += r * (elevations - zdet)\n                dest.write(np.where(elevations == src.nodata, np.nan, interpolation), 1)\n            else:\n                interpolation = compute_basic_interpolation((height, width),\n                                                            filtered, \n                                                            'hr' if data_field == 'humi' else 'v', \n                                                            (offset_h, offset_w))\n                dest.write(interpolation, 1)\n\n    # Export results to storage\n    out_key = os.path.join('tmp', data_field, tile_id, 'chunk_{}-{}'.format(block_x, block_y)) + '.tif'\n    with open('output', 'rb') as output_file:\n        storage.put_object(BUCKET, out_key, output_file)\n    \n    return out_key", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:39:01.538202Z", "start_time": "2021-04-13T14:39:01.521080Z"}, "trusted": true}, "execution_count": 25, "outputs": []}, {"cell_type": "markdown", "source": "Lithops serverless computation:", "metadata": {}}, {"cell_type": "code", "source": "lith = lithops.FunctionExecutor(backend='k8s', storage='ceph', runtime=RUNTIME, log_level=\"DEBUG\")", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T16:58:43.408027Z", "start_time": "2021-04-13T16:58:42.454398Z"}, "trusted": true}, "execution_count": 26, "outputs": [{"name": "stderr", "text": "2021-07-26 06:57:07,949 [INFO] lithops.config -- Lithops v2.3.6.dev0\n2021-07-26 06:57:07,951 [DEBUG] lithops.config -- Loading configuration from /home/jovyan/work/.lithops_config\n2021-07-26 06:57:07,959 [DEBUG] lithops.config -- Loading Serverless backend module: k8s\n2021-07-26 06:57:08,351 [DEBUG] lithops.config -- Loading Storage backend module: ceph\n2021-07-26 06:57:08,352 [DEBUG] lithops.storage.backends.ceph.ceph -- Creating Ceph client\n2021-07-26 06:57:08,354 [DEBUG] lithops.storage.backends.ceph.ceph -- Setting Ceph endpoint to http://10.24.17.56:7480\n2021-07-26 06:57:08,361 [INFO] lithops.storage.backends.ceph.ceph -- Ceph Storage client created - Endpoint: http://10.24.17.56:7480\n2021-07-26 06:57:08,362 [DEBUG] lithops.serverless.backends.k8s.k8s -- Creating Kubernetes Job client\n2021-07-26 06:57:08,389 [DEBUG] lithops.serverless.backends.k8s.k8s -- Set namespace to default\n2021-07-26 06:57:08,390 [DEBUG] lithops.serverless.backends.k8s.k8s -- Set cluster to kubernetes\n2021-07-26 06:57:08,391 [INFO] lithops.serverless.backends.k8s.k8s -- Kubernetes Job client created - Namespace: default\n2021-07-26 06:57:08,392 [DEBUG] lithops.invokers -- ExecutorID d706e5-0 - Total workers: 200\n2021-07-26 06:57:08,393 [INFO] lithops.executors -- Function executor for k8s created with ID: d706e5-0\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "iterdata = [('ceph://{}/MDT/{}.tif'.format(BUCKET, tile), i, j) \n            for i in range(SPLITS) for j in range(SPLITS) for tile in tiles]", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:39:28.155159Z", "start_time": "2021-04-13T14:39:28.150797Z"}, "tags": [], "trusted": true}, "execution_count": 27, "outputs": []}, {"cell_type": "code", "source": "pprint(iterdata)\nprint('Total functions: {} tiles * ({}^2) splits * 4 calculations = {}'.format(\n    len(tiles), SPLITS, len(iterdata) * 4))", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T14:39:28.850404Z", "start_time": "2021-04-13T14:39:28.812552Z"}, "trusted": true}, "execution_count": 28, "outputs": [{"name": "stdout", "text": "[('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0891_LID.tif', 0, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0892_LID.tif', 0, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0912_LID.tif', 0, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0913_LID.tif', 0, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0933_LID.tif', 0, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0934_LID.tif', 0, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0954_LID.tif', 0, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0955_LID.tif', 0, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0891_LID.tif', 0, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0892_LID.tif', 0, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0912_LID.tif', 0, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0913_LID.tif', 0, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0933_LID.tif', 0, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0934_LID.tif', 0, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0954_LID.tif', 0, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0955_LID.tif', 0, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0891_LID.tif', 0, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0892_LID.tif', 0, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0912_LID.tif', 0, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0913_LID.tif', 0, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0933_LID.tif', 0, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0934_LID.tif', 0, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0954_LID.tif', 0, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0955_LID.tif', 0, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0891_LID.tif', 1, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0892_LID.tif', 1, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0912_LID.tif', 1, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0913_LID.tif', 1, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0933_LID.tif', 1, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0934_LID.tif', 1, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0954_LID.tif', 1, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0955_LID.tif', 1, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0891_LID.tif', 1, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0892_LID.tif', 1, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0912_LID.tif', 1, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0913_LID.tif', 1, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0933_LID.tif', 1, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0934_LID.tif', 1, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0954_LID.tif', 1, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0955_LID.tif', 1, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0891_LID.tif', 1, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0892_LID.tif', 1, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0912_LID.tif', 1, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0913_LID.tif', 1, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0933_LID.tif', 1, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0934_LID.tif', 1, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0954_LID.tif', 1, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0955_LID.tif', 1, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0891_LID.tif', 2, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0892_LID.tif', 2, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0912_LID.tif', 2, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0913_LID.tif', 2, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0933_LID.tif', 2, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0934_LID.tif', 2, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0954_LID.tif', 2, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0955_LID.tif', 2, 0),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0891_LID.tif', 2, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0892_LID.tif', 2, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0912_LID.tif', 2, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0913_LID.tif', 2, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0933_LID.tif', 2, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0934_LID.tif', 2, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0954_LID.tif', 2, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0955_LID.tif', 2, 1),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0891_LID.tif', 2, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0892_LID.tif', 2, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0912_LID.tif', 2, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0913_LID.tif', 2, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0933_LID.tif', 2, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0934_LID.tif', 2, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0954_LID.tif', 2, 2),\n ('ceph://geospatial-usecase/MDT/PNOA_MDT05_ETRS89_HU30_0955_LID.tif', 2, 2)]\nTotal functions: 8 tiles * (3^2) splits * 4 calculations = 288\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "fut = lith.map(radiation_interpolation, iterdata, extra_args=(SPLITS,), runtime_memory=2048)", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T06:56:29.270356Z", "start_time": "2021-04-08T06:56:27.066344Z"}, "trusted": true}, "execution_count": 29, "outputs": [{"name": "stderr", "text": "2021-07-26 06:57:08,758 [INFO] lithops.invokers -- ExecutorID d706e5-0 | JobID M000 - Selected Runtime: sergidomingo/geospatial-k8s:2 - 2048MB\n2021-07-26 06:57:08,761 [DEBUG] lithops.storage.storage -- Runtime metadata found in local cache\n", "output_type": "stream"}, {"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-29-3b8f521e8a32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlith\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradiation_interpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSPLITS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/lithops/executors.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_function, map_iterdata, chunksize, worker_processes, extra_args, extra_env, runtime_memory, chunk_size, chunk_n, obj_chunk_size, obj_chunk_number, timeout, invoke_pool_threads, include_modules, exclude_modules)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'map'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mruntime_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         job = create_map_job(config=self.config,\n", "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/lithops/invokers.py\u001b[0m in \u001b[0;36mselect_runtime\u001b[0;34m(self, job_id, runtime_memory)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Verify python version and lithops version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlithops_version\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mruntime_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lithops_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             raise Exception(\"Lithops version mismatch. Host version: {} - Runtime version: {}\"\n\u001b[0m\u001b[1;32m    129\u001b[0m                             .format(lithops_version, runtime_meta['lithops_version']))\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mException\u001b[0m: Lithops version mismatch. Host version: 2.3.6.dev0 - Runtime version: 2.3.2.dev1"], "ename": "Exception", "evalue": "Lithops version mismatch. Host version: 2.3.6.dev0 - Runtime version: 2.3.2.dev1", "output_type": "error"}]}, {"cell_type": "code", "source": "fut = lith.map(map_interpolation, iterdata, extra_args=(SPLITS,'temp'), runtime_memory=2048)", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T06:56:30.638547Z", "start_time": "2021-04-08T06:56:29.277666Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "fut = lith.map(map_interpolation, iterdata, extra_args=(SPLITS,'humi'), runtime_memory=2048)", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T06:56:32.429261Z", "start_time": "2021-04-08T06:56:31.673596Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "fut = lith.map(map_interpolation, iterdata, extra_args=(SPLITS,'wind'), runtime_memory=2048)", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T06:56:34.748102Z", "start_time": "2021-04-08T06:56:34.186500Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "out_chunks = lith.get_result()", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T07:00:51.123143Z", "start_time": "2021-04-08T06:56:40.139182Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "Join split subsets into a tile:", "metadata": {}}, {"cell_type": "code", "source": "def gather_blocks(tile, splits, data_field, storage):\n\n    from rasterio.windows import Window\n    \n    # Get width and height from original tile\n    with rasterio.open(storage.get_object(bucket=BUCKET, key=f'MDT/{tile}.tif', stream=True)) as og:\n        height = og.profile['height']\n        width = og.profile['width']\n    \n    chunk_tiles = storage.list_keys(bucket=BUCKET, prefix=f'tmp/{data_field}/{tile}/chunk')\n        \n    # Open first object to obtain profile metadata\n    with rasterio.open(storage.get_object(bucket=BUCKET, key=chunk_tiles[0], stream=True)) as src:\n        profile = src.profile\n        profile.update(width=width)\n        profile.update(height=height)\n\n    # Iterate each object and print its block into the destination file\n    with rasterio.open(\"output\", \"w\", **profile) as dest: \n        for chunk in chunk_tiles:\n            j, i = os.path.splitext(os.path.basename(chunk))[0].rsplit('_')[1].split('-')\n            j, i = int(j), int(i)\n            with rasterio.open(storage.get_object(bucket=BUCKET, key=chunk, stream=True)) as src:\n                step_w = math.floor(width / splits)\n                step_h = math.floor(height / splits)\n                curr_window = Window(round(step_w * i), round(step_h * j), src.width, src.height)\n                content = src.read(1)\n                dest.write(content, 1, window=curr_window)\n            # storage.delete_object(bucket=BUCKET, key=chunk)\n    \n    output_key = os.path.join('tmp', data_field, tile, '_'.join([tile, data_field.upper()+'.tif']))\n    with open('output', 'rb') as out_file:\n        storage.put_object(bucket=BUCKET, key=output_key, body=out_file)  \n    \n    return output_key", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T07:21:21.921233Z", "start_time": "2021-04-08T07:21:21.911497Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "Combine previous split subsets:", "metadata": {}}, {"cell_type": "code", "source": "lith.map(gather_blocks, tiles, extra_args=(SPLITS, 'extrad'), runtime_memory=2048)", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T07:21:43.580625Z", "start_time": "2021-04-08T07:21:43.180508Z"}, "scrolled": true, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "lith.map(gather_blocks, tiles, extra_args=(SPLITS, 'humi'), runtime_memory=2048)", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T07:21:44.784961Z", "start_time": "2021-04-08T07:21:44.401457Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "lith.map(gather_blocks, tiles, extra_args=(SPLITS, 'rad'), runtime_memory=2048)", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T07:21:45.855437Z", "start_time": "2021-04-08T07:21:45.488359Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "lith.map(gather_blocks, tiles, extra_args=(SPLITS, 'temp'), runtime_memory=2048)", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T07:21:46.912489Z", "start_time": "2021-04-08T07:21:46.515196Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "fut = lith.map(gather_blocks, tiles, extra_args=(SPLITS, 'wind'), runtime_memory=2048)", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T07:21:48.282075Z", "start_time": "2021-04-08T07:21:47.908570Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "out_combined = lith.get_result()", "metadata": {"ExecuteTime": {"end_time": "2021-04-08T07:22:14.948724Z", "start_time": "2021-04-08T07:21:52.356798Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## Computation of potential evaporation", "metadata": {}}, {"cell_type": "code", "source": "def compute_crop_evapotranspiration(temperatures,\n                                    humidities,\n                                    wind_speeds,\n                                    external_radiations,\n                                    global_radiations,\n                                    KCs):\n    gamma = 0.665*101.3/1000\n    eSat = 0.6108 * np.exp((17.27*temperatures)/(temperatures+237.3))\n    delta = 4098 * eSat / np.power((temperatures + 237.3),2)\n    eA = np.where(humidities < 0, 0, eSat * humidities / 100)     # Avoid sqrt of a negative number\n    T4 = 4.903 * np.power((273.3 + temperatures),4)/1000000000\n    rSrS0 = global_radiations/(external_radiations * 0.75)\n    rN = 0.8* global_radiations-T4*(0.34-0.14*np.sqrt(eA))*((1.35*rSrS0)-0.35)\n    den = delta + gamma *(1 + 0.34* wind_speeds)\n    tRad = 0.408 * delta * rN / den\n    tAdv = gamma * (900/(temperatures+273))*wind_speeds * (eSat - eA)/den\n    return ((tRad + tAdv) * 7 * KCs).astype('float32')", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T16:57:51.493674Z", "start_time": "2021-04-13T16:57:51.485032Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "vineyard = ['VI', 'VO', 'VF', 'FV', 'CV' ]\nolive_grove = ['OV', 'VO', 'OF', 'FL', 'OC']\nfruit = ['FY', 'VF', 'OF', 'FF', 'CF']\nnuts = ['FS', 'FV', 'FL', 'FF', 'CS' ]\ncitrus = ['CI', 'CV', 'OC', 'CF', 'CS' ]\n\ndef get_kc(feature):\n    \n    # TODO: Get more precise values of Kc\n    sigpac_use = feature['properties']['uso_sigpac']\n    if sigpac_use in vineyard:\n        # Grapes for wine - 0.3, 0.7, 0.45\n        return 0.7  \n    if sigpac_use in olive_grove:\n        # Olive grove - ini: 0.65, med: 0.7, end: 0.7\n        return 0.7 \n    if sigpac_use in fruit:\n        # Apples, Cherries, Pears - 0.45, 0.95, 0.7\n        return 0.95\n    if sigpac_use in nuts:\n        # Almonds - 0.4, 0.9, 0.65\n        return 0.9\n    if sigpac_use in citrus:\n        # Citrus, without ground coverage - 0.7, 0.65, 0.7\n        return 0.65\n    \n    return None", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T16:57:52.760441Z", "start_time": "2021-04-13T16:57:52.753812Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "def get_geometry_window(src, geom_bounds):\n    left, bottom, right, top = geom_bounds\n    src_left, src_bottom, src_right, src_top = src.bounds\n    window = src.window(max(left,src_left), max(bottom,src_bottom), min(right,src_right), min(top,src_top))\n    window_floored = window.round_offsets(op='floor', pixel_precision=3)\n    w = math.ceil(window.width + window.col_off - window_floored.col_off)\n    h = math.ceil(window.height + window.row_off - window_floored.row_off)\n    return Window(window_floored.col_off, window_floored.row_off, w, h)     ", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T16:57:54.250115Z", "start_time": "2021-04-13T16:57:54.243932Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "def compute_evapotranspiration_by_shape(tem, hum, win, rad, extrad, dst):\n    \n    import fiona\n    from shapely.geometry import shape, box\n    from rasterio import features\n    \n    non_arable_land = ['AG', 'CA', 'ED', 'FO', 'IM', 'PA', 'PR', 'ZU', 'ZV']\n    \n    with fiona.open('zip://shape.zip') as shape_src:\n        for feature in shape_src.filter(bbox=tem.bounds):\n            KC = get_kc(feature) \n            if KC is not None:   \n                geom = shape(feature['geometry'])  \n                window = get_geometry_window(tem, geom.bounds)              \n                win_transform = rasterio.windows.transform(window, tem.transform)\n                # Convert shape to raster matrix\n                image = features.rasterize([geom],\n                                           out_shape=(window.height, window.width),\n                                           transform = win_transform,\n                                           fill = 0,\n                                           default_value = 1).astype('bool')\n                # Get values to compute evapotranspiration\n                temperatures = tem.read(1, window=window)\n                humidities = hum.read(1, window=window)\n                wind_speeds = win.read(1, window=window)\n                # Convert from W to MJ (0.0036)\n                global_radiations = rad.read(1, window=window) * 0.0036\n                external_radiations = extrad.read(1, window=window) * 0.0036\n                KCs = np.full(temperatures.shape, KC)\n                # TODO: compute external radiation\n                #external_radiations = np.full(temperatures.shape, 14)\n                # TODO: compute global radiation\n                # global_radiations = np.full(temperatures.shape, 10)\n                etc = compute_crop_evapotranspiration(\n                        temperatures,\n                        humidities,\n                        wind_speeds,\n                        external_radiations,\n                        global_radiations,\n                        KCs\n                )\n                etc[temperatures == tem.nodata] = dst.nodata\n                etc[np.logical_not(image)] = dst.nodata\n                dst.write(etc + dst.read(1, window=window), 1, window=window)", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T16:57:57.781920Z", "start_time": "2021-04-13T16:57:57.770029Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "def compute_global_evapotranspiration(tem, hum, win, rad, extrad, dst):    \n    for ji, window in tem.block_windows(1):\n        bounds = rasterio.windows.bounds(window, tem.transform)\n        temperatures = tem.read(1, window=window)\n        humidities = hum.read(1, window=window)\n        wind_speeds = win.read(1, window=window)\n         # Convert from W to MJ (0.0036)\n        global_radiations = rad.read(1, window=window) * 0.0036\n        external_radiations = extrad.read(1, window=window) * 0.0036\n        # TODO: compute external radiation\n        #external_radiations = np.full(temperatures.shape, 14)\n        # TODO: compute global radiation\n        # global_radiations = np.full(temperatures.shape, 10)\n        # TODO: compute KCs\n        KCs = np.full(temperatures.shape, 1)\n        etc = compute_crop_evapotranspiration(\n                temperatures,\n                humidities,\n                wind_speeds,\n                external_radiations,\n                global_radiations,\n                KCs\n        )\n        dst.write(np.where(temperatures == tem.nodata, dst.nodata, etc), 1, window=window)", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T16:57:59.216824Z", "start_time": "2021-04-13T16:57:59.207435Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "def combine_calculations(tile, storage):\n    \n    from functools import partial\n      \n    # Download shapefile\n    shapefile = storage.get_object(bucket=BUCKET, key='shapefile.zip', stream=True)\n    with open('shape.zip', 'wb') as shapf:\n        for chunk in iter(partial(shapefile.read, 200 * 1024 * 1024), ''):\n            if not chunk:\n                break\n            shapf.write(chunk)\n    \n    temp = storage.get_object(bucket=BUCKET, key=f'tmp/temp/{tile}/{tile}_TEMP.tif', stream=True)\n    humi = storage.get_object(bucket=BUCKET, key=f'tmp/humi/{tile}/{tile}_HUMI.tif', stream=True)\n    rad = storage.get_object(bucket=BUCKET, key=f'tmp/rad/{tile}/{tile}_RAD.tif', stream=True)\n    extrad = storage.get_object(bucket=BUCKET, key=f'tmp/extrad/{tile}/{tile}_EXTRAD.tif', stream=True)\n    wind = storage.get_object(bucket=BUCKET, key=f'tmp/wind/{tile}/{tile}_WIND.tif', stream=True)\n    \n    with rasterio.open(temp) as temp_raster:\n        with rasterio.open(humi) as humi_raster:\n            with rasterio.open(rad) as rad_raster:\n                with rasterio.open(extrad) as extrad_raster:\n                    with rasterio.open(wind) as wind_raster:\n                        profile = temp_raster.profile\n                        profile.update(nodata=0)\n        \n                        with rasterio.open('output', 'w+', **profile) as dst:\n#                             compute_global_evapotranspiration(temp_raster, humi_raster, wind_raster,\n#                                                               rad_raster, extrad_raster, dst)\n                            compute_evapotranspiration_by_shape(temp_raster, humi_raster, wind_raster,\n                                                                rad_raster, extrad_raster, dst)\n    \n    out_key = f'etc/{tile}_ETC.tif'\n    with open('output', 'rb') as output_f:\n        storage.put_object(bucket=BUCKET, key=out_key, body=output_f)\n    return out_key", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T16:58:01.128416Z", "start_time": "2021-04-13T16:58:01.101842Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "fut = lith.map(combine_calculations, tiles, runtime_memory=2048)", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T16:58:55.822484Z", "start_time": "2021-04-13T16:58:54.943303Z"}, "scrolled": true, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "res = lith.get_result()", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T17:01:57.663322Z", "start_time": "2021-04-13T16:58:57.632356Z"}, "scrolled": true, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## Visualization of results", "metadata": {}}, {"cell_type": "code", "source": "import io\ntile = random.choice(tiles)\nobj = io.BytesIO(cloud_storage.get_object(bucket=BUCKET, key=f'etc/{tile}_ETC.tif'))", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T21:30:27.539704Z", "start_time": "2021-04-13T21:30:26.276005Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "from matplotlib import pyplot as plt\n\nfig, ax = plt.subplots()\n\nwith rasterio.open(obj) as src:\n    arr = src.read(1, out_shape=(src.height, src.width))\n    ax.set_title(tile)\n    img = ax.imshow(arr, cmap='Greens')\n    fig.colorbar(img, shrink=0.5)\n\nfig.set_size_inches(18.5, 10.5)\nplt.show()\n\nobj.seek(0)", "metadata": {"ExecuteTime": {"end_time": "2021-04-13T21:32:01.429761Z", "start_time": "2021-04-13T21:32:00.245568Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### Utility functions", "metadata": {}}, {"cell_type": "markdown", "source": "Remove intermediate data", "metadata": {}}, {"cell_type": "code", "source": "# keys = cloud_storage.list_keys(bucket=BUCKET, prefix='')\n# keys", "metadata": {"ExecuteTime": {"end_time": "2021-03-29T10:06:07.571233Z", "start_time": "2021-03-29T10:05:14.526Z"}, "trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# for key in keys:\n#     cloud_storage.delete_object(bucket=BUCKET, key=key)", "metadata": {"ExecuteTime": {"end_time": "2021-03-29T10:06:07.574068Z", "start_time": "2021-03-29T10:05:14.528Z"}, "trusted": true}, "execution_count": null, "outputs": []}]}